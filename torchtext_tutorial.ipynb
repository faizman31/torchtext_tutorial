{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torchtext Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 다운로드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-0. 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. IMDB 리뷰 데이터 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('IMDb_Reviews.csv', <http.client.HTTPMessage at 0x7fe4add8f4d0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/LawrenceDuan/IMDb-Review-Analysis/master/IMDb_Reviews.csv\", filename=\"IMDb_Reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My family and I normally do not watch local mo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Believe it or not, this was at one time the wo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>After some internet surfing, I found the \"Home...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One of the most unheralded great works of anim...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It was the Sixties, and anyone with long hair ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  My family and I normally do not watch local mo...          1\n",
       "1  Believe it or not, this was at one time the wo...          0\n",
       "2  After some internet surfing, I found the \"Home...          0\n",
       "3  One of the most unheralded great works of anim...          1\n",
       "4  It was the Sixties, and anyone with long hair ...          0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('./data/IMDb_Reviews.csv',encoding='latin1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 갯수: 50000\n"
     ]
    }
   ],
   "source": [
    "print('전체 샘플의 갯수: {}'.format(len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=df[:25000]\n",
    "test_df=df[25000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test csv 파일 저장\n",
    "# index=False로 하면 인덱스를 저장하지 않습니다.\n",
    "train_df.to_csv('./data/train_data.csv',index=False)\n",
    "test_df.to_csv('./data/test_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 필드 정의하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-0. torchtext 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.legacy import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. Field 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT=data.Field(\n",
    "    sequential=True,\n",
    "    use_vocab=True,\n",
    "    tokenize=str.split,\n",
    "    lower=True,\n",
    "    batch_first=True,\n",
    "    fix_length=20\n",
    ")\n",
    "\n",
    "LABEL=data.Field(\n",
    "    sequential=False,\n",
    "    use_vocab=False,\n",
    "    batch_first=False,\n",
    "    is_target=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 데이터셋 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1. torchtext 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.legacy.data import TabularDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. TabularDataset을 이용해 데이터셋 만들기\n",
    "- path : 파일 경로\n",
    "- train/test : train,test 파일 이름\n",
    "- format : 파일의 형태 (csv,tsv,json)\n",
    "- fields : 필드 정보\n",
    "- skip_header : 데이터의 첫번째 줄은 무시 (csv 파일의 경우 feature명)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data=TabularDataset.splits(\n",
    "    path='./data',\n",
    "    train='train_data.csv',test='test_data.csv',\n",
    "    format='csv',\n",
    "    fields=[('text',TEXT),('label',LABEL)],\n",
    "    skip_header=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플의 개수 : 25000\n",
      "테스트 샘플의 개수 : 25000\n"
     ]
    }
   ],
   "source": [
    "print('훈련 샘플의 개수 : {}'.format(len(train_data)))\n",
    "print('테스트 샘플의 개수 : {}'.format(len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['my', 'family', 'and', 'i', 'normally', 'do', 'not', 'watch', 'local', 'movies', 'for', 'the', 'simple', 'reason', 'that', 'they', 'are', 'poorly', 'made,', 'they', 'lack', 'the', 'depth,', 'and', 'just', 'not', 'worth', 'our', 'time.<br', '/><br', '/>the', 'trailer', 'of', '\"nasaan', 'ka', 'man\"', 'caught', 'my', 'attention,', 'my', 'daughter', 'in', \"law's\", 'and', \"daughter's\", 'so', 'we', 'took', 'time', 'out', 'to', 'watch', 'it', 'this', 'afternoon.', 'the', 'movie', 'exceeded', 'our', 'expectations.', 'the', 'cinematography', 'was', 'very', 'good,', 'the', 'story', 'beautiful', 'and', 'the', 'acting', 'awesome.', 'jericho', 'rosales', 'was', 'really', 'very', 'good,', \"so's\", 'claudine', 'barretto.', 'the', 'fact', 'that', 'i', 'despised', 'diether', 'ocampo', 'proves', 'he', 'was', 'effective', 'at', 'his', 'role.', 'i', 'have', 'never', 'been', 'this', 'touched,', 'moved', 'and', 'affected', 'by', 'a', 'local', 'movie', 'before.', 'imagine', 'a', 'cynic', 'like', 'me', 'dabbing', 'my', 'eyes', 'at', 'the', 'end', 'of', 'the', 'movie?', 'congratulations', 'to', 'star', 'cinema!!', 'way', 'to', 'go,', 'jericho', 'and', 'claudine!!'], 'label': '1'}\n"
     ]
    }
   ],
   "source": [
    "# vars() 함수를 통해 주어진 인덱스의 샘플을 확인 할 수 있다.\n",
    "print(vars(train_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('text', <torchtext.legacy.data.field.Field object at 0x7fe4add8f090>), ('label', <torchtext.legacy.data.field.Field object at 0x7fe4add8f050>)])\n"
     ]
    }
   ],
   "source": [
    "# 필드 구성 확인\n",
    "print(train_data.fields.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 단어집합 만들기\n",
    "- 토큰화 전처리가 끝난 후 각 단어에 고유한 정수를 맵핑해주는 정수 인코딩(Integer Encoding) 작업이 진행되어야 합니다 그 전에 각 단어에 고유한 정수를 부여하기 위해서는 단어 집합을 만들어주어야 합니다\n",
    "- 단어 집합 생성 : <필드명>.build_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data에 TEXT필드에 있는 것들을 단어집합으로 만들꺼야\n",
    "# 단어 집합에는 최소 10번이상 등장한 단어들을 넣어야 하고 단어집의 최대 크기는 10000이야\n",
    "TEXT.build_vocab(train_data,min_freq=10,max_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 10002\n"
     ]
    }
   ],
   "source": [
    "# Q) max_size를 10000개로 설정했는데 왜 10002?\n",
    "# A) <unk>,<pad> 와 같은 special token이 추가되었기 떄문입니다.\n",
    "print('단어 집합의 크기 : {}'.format(len(TEXT.vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 생성된 단어의 집합은 \"<필드명>.vocab.stoi\" 를 통해서 확인이 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(TEXT.vocab.stoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. torchtext를 활용한 데이터로더 만들기\n",
    "- 데이터로더의 역할 : 데이터로더는 데이터셋에서 미니배치만큼 데이터를 로드하게 만들어주는 역할을 합니다.\n",
    "- torchtext에서는 iterator를 사용하여 데이터로더를 생성합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-0. 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.legacy.data import Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=10\n",
    "train_loader=Iterator(dataset=train_data,batch_size=batch_size)\n",
    "test_loader=Iterator(dataset=test_data,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 미니배치의 갯수 : 2500\n",
      "테스트 데이터의 미니배치의 갯수 : 2500\n"
     ]
    }
   ],
   "source": [
    "# 25000 / 10 = 2500\n",
    "print('훈련 데이터의 미니배치의 갯수 : {}'.format(len(train_loader)))\n",
    "print('테스트 데이터의 미니배치의 갯수 : {}'.format(len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch=next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 일반적인 데이터로더의 경우 미니 배치를 텐서로 가져오지만 torchtext의 데이터로더는 torchtext.legacy.batch.Batch 객체로 가져오게 됩니다. 실제 데이터 텐서에 접근하기 위해서는 정확한 필드명을 사용해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchtext.legacy.data.batch.Batch'>\n"
     ]
    }
   ],
   "source": [
    "print(type(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  29,   48,  251,  114,    3,   25,  369,   38,   96,   43,    0, 1648,\n",
      "            8,   43,    0,    0, 1321,   47,   15,    3],\n",
      "        [   9,   61,  465,   10,  664,   34, 3871,    0,    2,  119,  850,    9,\n",
      "           91,  207,   63,    6, 1654,   11,   17,    7],\n",
      "        [  10,   20,    5,    0,  279,   14, 3943,   31,    2, 1039, 1228,  864,\n",
      "          273,    2,  366,    0,   11,  608,   24,    2],\n",
      "        [  44,  291,  268,   16,   32,  238,  211, 2771,   10,  212,   28,    2,\n",
      "           30,   16,  916,   43,  731,    4,   29,  290],\n",
      "        [1422,   10,   20,   14, 4333,    9,   83,   98,   11,   14,    2,  119,\n",
      "           20,  124,   95,   18,   11,  280,   14, 1546],\n",
      "        [   0,   11,  362,  126,   59,  996, 4771,  535,    4,   60, 1157,    3,\n",
      "         6866, 1162, 5675,  428,    7,    3, 4925, 2416],\n",
      "        [   9,  310,   42,   10,   20,    8,    3, 4748,    4,    9,   14,    0,\n",
      "            3, 1743,   35,   30,  359, 1035, 1045, 1693],\n",
      "        [   2,  320,   16,   10,   25,    7,   31,    0,    0, 1283,   12,  200,\n",
      "          201, 6594,    2,    0,  503,    0,    8,    0],\n",
      "        [   0,    0,   14,    3, 1116, 1711,    5,    2, 8255,  345,  752, 1652,\n",
      "           57,   41,  240, 1833, 3054, 4861,    4, 5654],\n",
      "        [1422,    9,  144,  115,   48,    6,  518,   50,    9,  202,    2, 1175,\n",
      "            6,    0, 1534,   50,    9,  317,  546,   11]])\n"
     ]
    }
   ],
   "source": [
    "print(batch.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3b78608c2e597662164c1431d33c223e3a96e505f71506bfb26a5d6d9b03be90"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('torchtext_tutorial')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
